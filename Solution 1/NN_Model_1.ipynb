{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>B1</th>\n",
       "      <th>C1</th>\n",
       "      <th>A2</th>\n",
       "      <th>B2</th>\n",
       "      <th>C2</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85</td>\n",
       "      <td>1.86</td>\n",
       "      <td>9.06</td>\n",
       "      <td>-5.04</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>6.03</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.80</td>\n",
       "      <td>-4.07</td>\n",
       "      <td>7.38</td>\n",
       "      <td>-6.07</td>\n",
       "      <td>-4.03</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.79</td>\n",
       "      <td>1.63</td>\n",
       "      <td>-2.08</td>\n",
       "      <td>-3.93</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-8.32</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.86</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.30</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>9.76</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.99</td>\n",
       "      <td>4.67</td>\n",
       "      <td>-5.29</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.32</td>\n",
       "      <td>-7.89</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4.53</td>\n",
       "      <td>-4.48</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-3.28</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-7.04</td>\n",
       "      <td>-7.88</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.43</td>\n",
       "      <td>6.61</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>8.44</td>\n",
       "      <td>9.15</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.65</td>\n",
       "      <td>7.98</td>\n",
       "      <td>3.75</td>\n",
       "      <td>-8.18</td>\n",
       "      <td>-4.98</td>\n",
       "      <td>5.12</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.75</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>7.66</td>\n",
       "      <td>1.43</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.45</td>\n",
       "      <td>3.07</td>\n",
       "      <td>5.82</td>\n",
       "      <td>2.71</td>\n",
       "      <td>-7.36</td>\n",
       "      <td>4.16</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.69</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>-7.96</td>\n",
       "      <td>8.90</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>7.07</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-7.25</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>3.51</td>\n",
       "      <td>-6.56</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-3.81</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-5.50</td>\n",
       "      <td>6.19</td>\n",
       "      <td>-7.67</td>\n",
       "      <td>3.51</td>\n",
       "      <td>-6.51</td>\n",
       "      <td>9.05</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.71</td>\n",
       "      <td>4.71</td>\n",
       "      <td>5.99</td>\n",
       "      <td>-9.65</td>\n",
       "      <td>7.83</td>\n",
       "      <td>-9.46</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-4.80</td>\n",
       "      <td>2.88</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-8.49</td>\n",
       "      <td>9.36</td>\n",
       "      <td>-4.83</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>-9.41</td>\n",
       "      <td>-9.04</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>7.68</td>\n",
       "      <td>2.34</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.03</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>7.69</td>\n",
       "      <td>3.96</td>\n",
       "      <td>4.96</td>\n",
       "      <td>-7.13</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.69</td>\n",
       "      <td>-3.90</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>-6.02</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.19</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-8.80</td>\n",
       "      <td>6.51</td>\n",
       "      <td>-2.64</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.45</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>-6.09</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>-8.40</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.04</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-9.06</td>\n",
       "      <td>-2.46</td>\n",
       "      <td>7.47</td>\n",
       "      <td>6.93</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.11</td>\n",
       "      <td>-3.22</td>\n",
       "      <td>8.88</td>\n",
       "      <td>-8.16</td>\n",
       "      <td>8.93</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.88</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>-8.49</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>-7.49</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.88</td>\n",
       "      <td>-6.45</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>8.60</td>\n",
       "      <td>-5.23</td>\n",
       "      <td>-8.67</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.14</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.36</td>\n",
       "      <td>1.55</td>\n",
       "      <td>9.94</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.76</td>\n",
       "      <td>9.48</td>\n",
       "      <td>2.37</td>\n",
       "      <td>4.63</td>\n",
       "      <td>6.72</td>\n",
       "      <td>7.73</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-7.05</td>\n",
       "      <td>5.15</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>8.60</td>\n",
       "      <td>-3.94</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-2.22</td>\n",
       "      <td>5.88</td>\n",
       "      <td>4.82</td>\n",
       "      <td>-8.32</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>6.90</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.56</td>\n",
       "      <td>-9.48</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-7.58</td>\n",
       "      <td>-3.77</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>5.93</td>\n",
       "      <td>3.07</td>\n",
       "      <td>-6.89</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-4.26</td>\n",
       "      <td>8.23</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>-6.29</td>\n",
       "      <td>4.78</td>\n",
       "      <td>-5.13</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>6.64</td>\n",
       "      <td>-9.70</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>-0.53</td>\n",
       "      <td>-7.16</td>\n",
       "      <td>1.57</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>7.18</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>-9.69</td>\n",
       "      <td>6.34</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-8.88</td>\n",
       "      <td>-2.40</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.71</td>\n",
       "      <td>-8.28</td>\n",
       "      <td>-5.93</td>\n",
       "      <td>4.35</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>4.82</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>1.93</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>2.53</td>\n",
       "      <td>-6.53</td>\n",
       "      <td>-7.83</td>\n",
       "      <td>2.27</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>-3.72</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-6.90</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>7.37</td>\n",
       "      <td>-8.37</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>-9.32</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.80</td>\n",
       "      <td>7.80</td>\n",
       "      <td>-6.02</td>\n",
       "      <td>-8.40</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>-9.00</td>\n",
       "      <td>7.84</td>\n",
       "      <td>-7.35</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>-8.70</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>-9.86</td>\n",
       "      <td>-8.95</td>\n",
       "      <td>-5.34</td>\n",
       "      <td>-3.44</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>-8.30</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.75</td>\n",
       "      <td>6.27</td>\n",
       "      <td>-9.86</td>\n",
       "      <td>-8.78</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>4.80</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.32</td>\n",
       "      <td>-3.02</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>-3.54</td>\n",
       "      <td>-5.61</td>\n",
       "      <td>-5.62</td>\n",
       "      <td>-5.44</td>\n",
       "      <td>-9.52</td>\n",
       "      <td>9.01</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>8.38</td>\n",
       "      <td>2.10</td>\n",
       "      <td>9.38</td>\n",
       "      <td>5.50</td>\n",
       "      <td>-8.69</td>\n",
       "      <td>4.91</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>-3.70</td>\n",
       "      <td>5.96</td>\n",
       "      <td>-4.45</td>\n",
       "      <td>4.88</td>\n",
       "      <td>9.03</td>\n",
       "      <td>-7.33</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>8.62</td>\n",
       "      <td>-8.94</td>\n",
       "      <td>-2.62</td>\n",
       "      <td>-6.56</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>-2.98</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1.52</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-4.67</td>\n",
       "      <td>-9.10</td>\n",
       "      <td>-5.44</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>4.02</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-5.18</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>9.86</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.66</td>\n",
       "      <td>9.47</td>\n",
       "      <td>-3.02</td>\n",
       "      <td>-7.21</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>6.24</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>-8.33</td>\n",
       "      <td>8.80</td>\n",
       "      <td>-2.46</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>-9.02</td>\n",
       "      <td>7.71</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>-10.00</td>\n",
       "      <td>7.87</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-3.36</td>\n",
       "      <td>-3.27</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>-1.77</td>\n",
       "      <td>2.68</td>\n",
       "      <td>-8.79</td>\n",
       "      <td>-8.97</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>-2.69</td>\n",
       "      <td>6.46</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>8.12</td>\n",
       "      <td>4.45</td>\n",
       "      <td>8.57</td>\n",
       "      <td>1.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>8.86</td>\n",
       "      <td>-9.64</td>\n",
       "      <td>4.12</td>\n",
       "      <td>-5.40</td>\n",
       "      <td>-8.38</td>\n",
       "      <td>-9.23</td>\n",
       "      <td>2.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>9.64</td>\n",
       "      <td>-9.57</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.53</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>6.23</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>7.93</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-2.05</td>\n",
       "      <td>-8.71</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.72</td>\n",
       "      <td>-2.97</td>\n",
       "      <td>-8.79</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>5.27</td>\n",
       "      <td>7.81</td>\n",
       "      <td>4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-7.91</td>\n",
       "      <td>-9.72</td>\n",
       "      <td>-4.95</td>\n",
       "      <td>1.64</td>\n",
       "      <td>-7.56</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>9.79</td>\n",
       "      <td>6.48</td>\n",
       "      <td>3.52</td>\n",
       "      <td>2.32</td>\n",
       "      <td>1.37</td>\n",
       "      <td>6.79</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>3.50</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.96</td>\n",
       "      <td>-6.46</td>\n",
       "      <td>8.93</td>\n",
       "      <td>-6.73</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A1    B1    C1    A2    B2    C2  Distance\n",
       "0      0.85  1.86  9.06 -5.04 -0.96  6.03      5.75\n",
       "1     -9.80 -4.07  7.38 -6.07 -4.03  2.68      0.41\n",
       "2      2.79  1.63 -2.08 -3.93  1.40 -8.32      3.32\n",
       "3     -5.86  0.05  6.30 -3.15  9.76  2.03      0.76\n",
       "4      0.47  0.93  1.99  4.67 -5.29 -5.50      4.12\n",
       "5      7.32 -7.89  0.50  3.99  4.53 -4.48      0.68\n",
       "6     -3.28 -2.96 -0.29  0.95 -7.04 -7.88      0.49\n",
       "7      7.43  6.61 -1.29  8.44  9.15  4.83      0.52\n",
       "8      8.65  7.98  3.75 -8.18 -4.98  5.12      2.57\n",
       "9     -0.75 -2.51 -2.70 -2.42  7.66  1.43      3.11\n",
       "10     4.45  3.07  5.82  2.71 -7.36  4.16      2.53\n",
       "11     9.69 -4.80 -7.96  8.90 -1.79  7.07      1.85\n",
       "12    -7.25 -1.41  3.51 -6.56  0.35 -3.81      0.83\n",
       "13    -5.50  6.19 -7.67  3.51 -6.51  9.05      1.66\n",
       "14     4.71  4.71  5.99 -9.65  7.83 -9.46      3.22\n",
       "15    -4.80  2.88 -0.94 -8.49  9.36 -4.83      0.20\n",
       "16    -0.07 -9.41 -9.04 -1.27  7.68  2.34      3.09\n",
       "17     4.03 -1.37  7.69  3.96  4.96 -7.13      2.15\n",
       "18     1.69 -3.90 -2.37 -6.02 -1.63  5.92      0.80\n",
       "19     3.19  0.76 -0.31 -8.80  6.51 -2.64      1.56\n",
       "20     7.45 -1.34 -6.09 -3.11 -8.40  4.44      0.79\n",
       "21     7.04 -0.00 -9.06 -2.46  7.47  6.93      1.81\n",
       "22     8.11 -3.22  8.88 -8.16  8.93  2.48      1.31\n",
       "23     0.88 -1.21 -8.49 -6.00 -7.49 -0.78      4.41\n",
       "24     9.88 -6.45 -6.18  8.60 -5.23 -8.67      0.29\n",
       "25     6.14  4.54  4.36  1.55  9.94  4.85      0.35\n",
       "26     3.76  9.48  2.37  4.63  6.72  7.73      0.81\n",
       "27    -7.05  5.15 -0.90 -3.12  8.60 -3.94      0.49\n",
       "28    -2.22  5.88  4.82 -8.32 -0.51  6.90      1.58\n",
       "29     1.56 -9.48  0.91 -7.58 -3.77  6.07      0.11\n",
       "...     ...   ...   ...   ...   ...   ...       ...\n",
       "971    5.93  3.07 -6.89  2.00 -4.26  8.23      0.95\n",
       "972   -6.29  4.78 -5.13 -1.38  6.64 -9.70      0.19\n",
       "973   -0.53 -7.16  1.57 -0.34  7.18 -1.21      1.64\n",
       "974   -9.69  6.34  0.33 -8.88 -2.40  6.25      0.29\n",
       "975    0.71 -8.28 -5.93  4.35 -0.82  4.82      3.51\n",
       "976    1.93 -0.41  2.53 -6.53 -7.83  2.27      3.24\n",
       "977   -3.72 -0.72 -6.90 -0.34  7.37 -8.37      2.81\n",
       "978   -9.32 -0.12  0.80  7.80 -6.02 -8.40      0.26\n",
       "979   -9.00  7.84 -7.35  0.17 -5.92 -8.70      1.73\n",
       "980   -9.86 -8.95 -5.34 -3.44 -1.52 -1.84      0.01\n",
       "981   -8.30  0.53  9.75  6.27 -9.86 -8.78      1.30\n",
       "982    4.80  3.07  8.32 -3.02 -0.70  8.50      1.30\n",
       "983   -3.54 -5.61 -5.62 -5.44 -9.52  9.01      1.68\n",
       "984    8.38  2.10  9.38  5.50 -8.69  4.91      2.13\n",
       "985   -3.70  5.96 -4.45  4.88  9.03 -7.33      0.95\n",
       "986    8.62 -8.94 -2.62 -6.56 -3.41 -2.98      1.51\n",
       "987    1.52  3.96  0.81 -4.67 -9.10 -5.44      3.36\n",
       "988    4.02  0.43 -5.18 -3.16 -1.73  9.86      1.56\n",
       "989    0.66  9.47 -3.02 -7.21 -3.24  6.24      1.28\n",
       "990   -8.33  8.80 -2.46 -1.49 -9.02  7.71      0.14\n",
       "991  -10.00  7.87 -0.08 -3.36 -3.27  0.12      1.21\n",
       "992   -1.77  2.68 -8.79 -8.97 -0.48  2.47      1.68\n",
       "993   -2.69  6.46 -1.02  8.12  4.45  8.57      1.89\n",
       "994    8.86 -9.64  4.12 -5.40 -8.38 -9.23      2.56\n",
       "995   -1.00  9.64 -9.57  3.79  3.06  3.53      2.23\n",
       "996    6.23 -0.43  7.93 -6.37 -2.05 -8.71      4.76\n",
       "997    1.72 -2.97 -8.79 -2.27  5.27  7.81      4.81\n",
       "998   -7.91 -9.72 -4.95  1.64 -7.56  1.00      1.17\n",
       "999    9.79  6.48  3.52  2.32  1.37  6.79      2.20\n",
       "1000   3.50  0.95  1.96 -6.46  8.93 -6.73      2.15\n",
       "\n",
       "[1001 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Distance_file_1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df[['A1','B1','C1','A2','B2','C2']]\n",
    "y = df['Distance']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(6, input_shape=(6,), activation=\"relu\"),\n",
    "    Dense(3, activation='relu'),\n",
    "    Dense(1,activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 12.6284 - val_loss: 11.8109\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 9.5128 - val_loss: 9.6019\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.7300 - val_loss: 8.3100\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 6.6526 - val_loss: 7.5367\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 5.9466 - val_loss: 6.9996\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.4189 - val_loss: 6.5957\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 5.0248 - val_loss: 6.2578\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 4.7053 - val_loss: 6.0064\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 4.4690 - val_loss: 5.7768\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 4.2695 - val_loss: 5.5827\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 4.1028 - val_loss: 5.4218\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 3.9602 - val_loss: 5.2819\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.8349 - val_loss: 5.1516\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 3.7237 - val_loss: 5.0361\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.6306 - val_loss: 4.9223\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 3.5426 - val_loss: 4.8266\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.4635 - val_loss: 4.7447\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 3.3982 - val_loss: 4.6650\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.3331 - val_loss: 4.5836\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 3.2732 - val_loss: 4.5168\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.2199 - val_loss: 4.4441\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 3.1663 - val_loss: 4.3832\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 3.1222 - val_loss: 4.3282\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 3.0800 - val_loss: 4.2688\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 3.0340 - val_loss: 4.2230\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.9950 - val_loss: 4.1707\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.9571 - val_loss: 4.1280\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.9227 - val_loss: 4.0816\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.8917 - val_loss: 4.0394\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.8590 - val_loss: 3.9864\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.8261 - val_loss: 3.9449\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.7943 - val_loss: 3.9074\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.7641 - val_loss: 3.8645\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.7309 - val_loss: 3.8100\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.6971 - val_loss: 3.7715\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.6663 - val_loss: 3.7315\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.6359 - val_loss: 3.6966\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.6061 - val_loss: 3.6535\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.5758 - val_loss: 3.6094\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.5467 - val_loss: 3.5657\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.5192 - val_loss: 3.5297\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.4942 - val_loss: 3.4970\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.4718 - val_loss: 3.4670\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.4448 - val_loss: 3.4386\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.4195 - val_loss: 3.4075\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.3940 - val_loss: 3.3722\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.3648 - val_loss: 3.3514\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.3367 - val_loss: 3.3114\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.3115 - val_loss: 3.2872\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.2800 - val_loss: 3.2664\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.2495 - val_loss: 3.2463\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.2074 - val_loss: 3.2066\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.1731 - val_loss: 3.1953\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.1315 - val_loss: 3.1676\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.0922 - val_loss: 3.1431\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.0533 - val_loss: 3.1173\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.0165 - val_loss: 3.1093\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.9816 - val_loss: 3.0727\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.9412 - val_loss: 3.0542\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.9048 - val_loss: 3.0399\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.8682 - val_loss: 3.0177\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.8380 - val_loss: 2.9996\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.8059 - val_loss: 2.9874\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.7689 - val_loss: 2.9625\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.7416 - val_loss: 2.9570\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.7169 - val_loss: 2.9452\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.6911 - val_loss: 2.9233\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.6659 - val_loss: 2.9261\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.6431 - val_loss: 2.9131\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.6254 - val_loss: 2.9024\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.6097 - val_loss: 2.8908\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.5935 - val_loss: 2.8862\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.5794 - val_loss: 2.8751\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.5685 - val_loss: 2.8729\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.5625 - val_loss: 2.8711\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.5469 - val_loss: 2.8645\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.5355 - val_loss: 2.8607\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.5281 - val_loss: 2.8579\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.5165 - val_loss: 2.8467\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.5129 - val_loss: 2.8442\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.5049 - val_loss: 2.8302\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.4991 - val_loss: 2.8279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.4860 - val_loss: 2.8203\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.4871 - val_loss: 2.8190\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.4747 - val_loss: 2.8159\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.4749 - val_loss: 2.8149\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.4641 - val_loss: 2.7984\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.4615 - val_loss: 2.7956\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.4564 - val_loss: 2.7971\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.4528 - val_loss: 2.7912\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.4462 - val_loss: 2.7875\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.4444 - val_loss: 2.7808\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.4428 - val_loss: 2.7832\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.4417 - val_loss: 2.7789\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.4372 - val_loss: 2.7818\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.4344 - val_loss: 2.7770\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.4331 - val_loss: 2.7748\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.4289 - val_loss: 2.7709\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.4269 - val_loss: 2.7727\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 1.4258 - val_loss: 2.7687\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "run_hist_1 = model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x237c5bc5940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('NN_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "A1=[]\n",
    "B1=[]\n",
    "C1=[]\n",
    "A2=[]\n",
    "B2=[]\n",
    "C2=[]\n",
    "distance=[]\n",
    "\n",
    "def Distance(a1,b1,c1,a2,b2,c2):\n",
    "    A1.append(a1)\n",
    "    B1.append(b1)\n",
    "    C1.append(c1)\n",
    "    A2.append(a2)\n",
    "    B2.append(b2)\n",
    "    C2.append(c2)\n",
    "\n",
    "\n",
    "    Data = pd.DataFrame()\n",
    "    Data['A1'] = A1\n",
    "    Data['B1'] = B1\n",
    "    Data['C1'] = C1\n",
    "    Data['A2'] = A2\n",
    "    Data['B2'] = B2\n",
    "    Data['C2'] = C2\n",
    "\n",
    "    saved_model = load_model('NN_model_1.h5')\n",
    "    test_result =saved_model.predict(Data)\n",
    "    print(\"Distance between 2 line=\",test_result)\n",
    "    distance.append(test_result)\n",
    "    Data['Distance'] = distance\n",
    "    print(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between 2 line= [[2.459477]]\n",
      "     A1    B1    C1    A2   B2    C2      Distance\n",
      "0  2.79  1.63 -2.08 -3.93  1.4 -8.32  [[2.459477]]\n"
     ]
    }
   ],
   "source": [
    "Distance(2.79,1.63,-2.08,-3.93,1.40,-8.32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
